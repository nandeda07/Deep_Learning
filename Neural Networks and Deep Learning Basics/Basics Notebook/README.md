### 01-Logistic-Regression-as-a-Neural-Network
    1  Binary Classification
    2  Logistic Regression
    3  Logistic Regression Cost Function
    4  Gradient Descent
    5  Computational Graph
    6  Logistic Regression Gradient Descent
    7  Logistic Regression on m examples

### 02-Vectorization
    1  Vectorization
    2  Vectorizing Logistic Regression
    3  Vectorizing Logistic Regression's Gradient Output
    4  A note on python/numpy vectors

### 03-Shallow-Neural-Network
    1  Neural Networks Overview
    2  Neural Network Representation
    3  Computing a Neural Network's Output
    4  Vectorizing across multiple examples
    5  Explanation for Vectorized Implementation
    6  Activation functions
    7  Why do you need non-linear activation functions?
    8  Derivatives of activation functions
        8.1  Sigmoid activation Function
        8.2  Tanh activation Function
        8.3  Relu and Leaky Relu activation Functions
    9  Gradient descent for Neural Networks
    10  Backpropagation intuition
    11  Random Initialization


### 04-Deep-Neural-Networks
    1  Deep L-layer neural network
    2  Forward and Backward Propagation
    3  Forward Propagation in a Deep Network
    4  Getting your matrix dimensions right
    5  Why deep representations?
    6  Building blocks of deep neural networks
    7  Parameters vs Hyperparameters
    8  What does this have to do with the brain?